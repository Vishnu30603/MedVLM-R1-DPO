{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y transformers\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "\n",
        "!pip install accelerate\n",
        "\n",
        "!pip install qwen-vl-utils\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "qDeoJIBguAw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSxoujOvDJKB",
        "outputId": "ea7a370a-51ff-4aaa-b30c-39ee6ea009df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/OmniMedVQA/Images.zip'\n",
        "extract_dir = '/content/Images'\n",
        "\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
        "    file_list = zipf.namelist()\n",
        "    for member in tqdm(file_list, desc=\"Unzipping images\"):\n",
        "        if member.endswith('/'):\n",
        "            continue\n",
        "        if member.startswith('Images/'):\n",
        "            target = member[len('Images/'):]\n",
        "        else:\n",
        "            target = member\n",
        "        target_path = os.path.join(extract_dir, target)\n",
        "        os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
        "        with zipf.open(member) as source, open(target_path, \"wb\") as dest:\n",
        "            shutil.copyfileobj(source, dest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9lnswcQDM08",
        "outputId": "715137fb-fcef-4597-85db-838ba4e8cc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unzipping images: 100%|██████████| 6675/6675 [00:09<00:00, 690.70it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "HWNowKF1ty1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, GenerationConfig\n",
        "from qwen_vl_utils import process_vision_info\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Paths\n",
        "csv_dir = '/content/drive/MyDrive/OmniMedVQA/CSV_Files'\n",
        "csv_paths = {\n",
        "    'MRI': f\"{csv_dir}/test_mri.csv\",\n",
        "    'CT': f\"{csv_dir}/test_ct.csv\",\n",
        "    'X-ray': f\"{csv_dir}/test_xray.csv\"\n",
        "}\n",
        "\n",
        "# Load model and processor\n",
        "MODEL_PATH = 'JZPeterPan/MedVLM-R1'\n",
        "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto',\n",
        ")\n",
        "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    max_new_tokens=128,\n",
        "    do_sample=False,\n",
        "    temperature=1,\n",
        "    num_return_sequences=1,\n",
        "    pad_token_id=151643,\n",
        ")\n",
        "\n",
        "# Prompt & CoT functions\n",
        "def construct_prompt(row):\n",
        "    return (\n",
        "        f\"{row['question']}\\n\"\n",
        "        f\"A) {row['option_A']}\\n\"\n",
        "        f\"B) {row['option_B']}\\n\"\n",
        "        f\"C) {row['option_C']}\\n\"\n",
        "        f\"D) {row['option_D']}\\n\"\n",
        "        \"First, think through the question step by step, enclose your reasoning process in <think>...</think> tags. \"\n",
        "        \"Then provide the correct single-letter choice (A, B, C, D,...) inside <answer>...</answer> tags.\"\n",
        "    )\n",
        "\n",
        "def extract_answer(text):\n",
        "    match = re.search(r\"<answer>\\s*([A-D])\\s*</answer>\", text)\n",
        "    return match.group(1) if match else \"?\"\n",
        "\n",
        "def generate_cot(image_path, question_text):\n",
        "    try:\n",
        "        message = [{\n",
        "            'role': 'user',\n",
        "            'content': [\n",
        "                {'type': 'image', 'image': f'file://{image_path}'},\n",
        "                {'type': 'text', 'text': question_text}\n",
        "            ]\n",
        "        }]\n",
        "        text = processor.apply_chat_template(message, tokenize=False, add_generation_prompt=True)\n",
        "        image_inputs, video_inputs = process_vision_info(message)\n",
        "        if not image_inputs or image_inputs[0] is None:\n",
        "            return \"ERROR: No valid image\"\n",
        "        inputs = processor(\n",
        "            text=text,\n",
        "            images=image_inputs,\n",
        "            videos=video_inputs,\n",
        "            padding=True,\n",
        "            return_tensors='pt',\n",
        "        ).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            generated_ids = model.generate(**inputs, use_cache=True, generation_config=generation_config)\n",
        "        output_ids = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
        "        decoded = processor.batch_decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
        "        return decoded[0]\n",
        "    except Exception as e:\n",
        "        return f\"ERROR: {type(e).__name__}: {str(e)}\"\n",
        "\n",
        "# Process each modality\n",
        "for modality, path in csv_paths.items():\n",
        "    print(f\"\\n--- Processing {modality} test set ---\")\n",
        "\n",
        "    df = pd.read_csv(path)\n",
        "    df['abs_image_path'] = df['image_path'].apply(lambda x: '/content/' + x if not x.startswith('/content/') else x)\n",
        "    df = df[df['abs_image_path'].apply(os.path.isfile)].reset_index(drop=True)\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"CoT: {modality}\"):\n",
        "        img_path = row['abs_image_path']\n",
        "        prompt = construct_prompt(row)\n",
        "        cot = generate_cot(img_path, prompt)\n",
        "        pred = extract_answer(cot)\n",
        "\n",
        "        # Map predicted letter to answer text\n",
        "        option_map = {\n",
        "            'A': row['option_A'],\n",
        "            'B': row['option_B'],\n",
        "            'C': row['option_C'],\n",
        "            'D': row['option_D'],\n",
        "        }\n",
        "        pred_answer_text = option_map.get(pred, \"\").strip().lower()\n",
        "        gt_answer_text = str(row['gt_answer']).strip().lower()\n",
        "        is_correct = pred_answer_text == gt_answer_text\n",
        "\n",
        "        predictions.append((cot, pred, pred_answer_text, gt_answer_text, is_correct))\n",
        "\n",
        "        if idx < 3:\n",
        "            print(f\"\\n--- Sample {idx+1} ---\")\n",
        "            print(f\"Q: {row['question']}\")\n",
        "            print(f\"Predicted: {pred} -> {pred_answer_text}\")\n",
        "            print(f\"Ground Truth: {gt_answer_text}\")\n",
        "            print(f\"Correct: {is_correct}\")\n",
        "            print(\"Output:\\n\", cot)\n",
        "\n",
        "    df['cot_output'] = [x[0] for x in predictions]\n",
        "    df['prediction'] = [x[1] for x in predictions]\n",
        "    df['pred_answer_text'] = [x[2] for x in predictions]\n",
        "    df['gt_answer_text'] = [x[3] for x in predictions]\n",
        "    df['is_correct'] = [x[4] for x in predictions]\n",
        "    accuracy = sum(df['is_correct']) / len(df) * 100\n",
        "\n",
        "    print(f\"\\nAccuracy on {modality} (n={len(df)}): {accuracy:.2f}%\")\n",
        "\n",
        "    out_path = path.replace(\".csv\", \"_with_cot_accuracy.csv\")\n",
        "    df.to_csv(out_path, index=False)\n",
        "    print(f\"Saved annotated results to: {out_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv1rQ3mw1zgZ",
        "outputId": "20bc2493-2e51-4c93-b8a0-43438735cde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
            "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Processing MRI test set ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CoT: MRI:   0%|          | 0/300 [00:00<?, ?it/s]`generation_config` default values have been modified to match model-specific defaults: {'do_sample': True, 'use_cache': None, 'temperature': 0.01, 'top_k': 1, 'top_p': 0.001, 'bos_token_id': 151643, 'eos_token_id': [151645, 151643], 'attn_implementation': 'flash_attention_2'}. If this is not desired, please set these values explicitly.\n",
            "CoT: MRI:   0%|          | 1/300 [00:06<34:12,  6.86s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "Q: What can be observed in this image?\n",
            "Predicted: A -> bone inflammation.\n",
            "Ground Truth: bone inflammation.\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image is a magnetic resonance imaging (MRI) scan of a knee joint. The scan shows a clear view of the knee, including the patella (knee cap), the femoral condyles (the flat surfaces of the femur bone), and the patellar ligament.\n",
            "</think>\n",
            "\n",
            "<answer>A</answer>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCoT: MRI:   1%|          | 2/300 [00:10<25:33,  5.15s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 2 ---\n",
            "Q: What can be observed in this image?\n",
            "Predicted: D -> achilles tendonitis\n",
            "Ground Truth: deltoid pathology\n",
            "Correct: False\n",
            "Output:\n",
            " <think>\n",
            "The image is a magnetic resonance imaging (MRI) scan of a foot, specifically focusing on the Achilles tendon. The scan shows a thickened and inflamed appearance of the Achilles tendon, which is a common finding in Achilles tendonitis.\n",
            "</think>\n",
            "\n",
            "<answer>D</answer>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCoT: MRI:   1%|          | 3/300 [00:14<22:55,  4.63s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 3 ---\n",
            "Q: What can be observed in this image?\n",
            "Predicted: D -> foraminal pathology\n",
            "Ground Truth: foraminal pathology\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image is a magnetic resonance imaging (MRI) scan of the lumbar spine. The scan shows a bony structure with a central area of high signal intensity, which is characteristic of an epidural hematoma.\n",
            "</think>\n",
            "\n",
            "<answer>D</answer>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CoT: MRI: 100%|██████████| 300/300 [23:03<00:00,  4.61s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy on MRI (n=300): 94.67%\n",
            "Saved annotated results to: /content/drive/MyDrive/OmniMedVQA/CSV_Files/test_mri_with_cot_accuracy.csv\n",
            "\n",
            "--- Processing CT test set ---\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CoT: CT:   0%|          | 1/300 [00:04<21:04,  4.23s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "Q: What is the term referring to the abnormality observed in the image?\n",
            "Predicted: A -> airspace opacity\n",
            "Ground Truth: airspace opacity\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image shows a CT scan of the chest, which is commonly used to diagnose various lung conditions. The abnormality observed in the image appears as a consolidation, which is a term used to describe a localized area of increased lung density.\n",
            "</think>\n",
            "\n",
            "<answer>A</answer>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCoT: CT:   1%|          | 2/300 [00:07<19:25,  3.91s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 2 ---\n",
            "Q: Is there any presence of abnormalities observed in this image?\n",
            "Predicted: A -> yes.\n",
            "Ground Truth: no\n",
            "Correct: False\n",
            "Output:\n",
            " <think>\n",
            "The image appears to be a cross-sectional view of a medical scan, likely a CT (Computed Tomography) scan of the chest. The scan shows a dense area in the center, which could be interpreted as a mass or abnormality.\n",
            "</think>\n",
            "\n",
            "<answer>A</answer>\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rCoT: CT:   1%|          | 3/300 [00:13<23:29,  4.75s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Sample 3 ---\n",
            "Q: What abnormal finding can be observed in the radiograph?\n",
            "Predicted: D -> osseous pathology\n",
            "Ground Truth: arterial pathology\n",
            "Correct: False\n",
            "Output:\n",
            " <think>\n",
            "The radiograph shows a cross-sectional view of the abdomen, which is a common imaging technique used in medical diagnostics. The presence of various anatomical structures such as the liver, spleen, and intestines suggests that the radiograph is likely an abdominal CT scan.\n",
            "</think>\n",
            "\n",
            "<answer>D</answer>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CoT: CT: 100%|██████████| 300/300 [37:42<00:00,  7.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on CT (n=300): 76.67%\n",
            "Saved annotated results to: /content/drive/MyDrive/OmniMedVQA/CSV_Files/test_ct_with_cot_accuracy.csv\n",
            "\n",
            "--- Processing X-ray test set ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CoT: X-ray:   0%|          | 1/300 [00:11<55:13, 11.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 1 ---\n",
            "Q: What type of abnormality is depicted in this image?\n",
            "Predicted: B -> no, it's normal\n",
            "Ground Truth: no, it's normal\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image is a mammogram, which is a type of X-ray used to detect abnormalities in the breast. The mammogram shows the breast tissue in detail, and the presence of dense tissue and calcifications is typical.\n",
            "</think>\n",
            "\n",
            "<answer>B</answer>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCoT: X-ray:   1%|          | 2/300 [00:19<46:17,  9.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 2 ---\n",
            "Q: What imaging technique is employed to obtain this picture?\n",
            "Predicted: C -> x_ray.\n",
            "Ground Truth: x_ray.\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image is a radiographic view of a knee, which is a common imaging technique used to visualize the bones and soft tissues of the body. The clarity and structure of the bones and soft tissues are indicative of a radiographic procedure.\n",
            "</think>\n",
            "\n",
            "<answer>C</answer>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rCoT: X-ray:   1%|          | 3/300 [00:24<36:33,  7.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Sample 3 ---\n",
            "Q: What modality is used to capture this image?\n",
            "Predicted: A -> x_ray.\n",
            "Ground Truth: x_ray.\n",
            "Correct: True\n",
            "Output:\n",
            " <think>\n",
            "The image appears to be a radiographic image, likely taken using a radiographic modality. The clarity and structure suggest it is a medical imaging technique used to visualize internal structures.\n",
            "</think>\n",
            "\n",
            "<answer>A</answer>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CoT: X-ray: 100%|██████████| 300/300 [55:08<00:00, 11.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy on X-ray (n=300): 77.33%\n",
            "Saved annotated results to: /content/drive/MyDrive/OmniMedVQA/CSV_Files/test_xray_with_cot_accuracy.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}