{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 50,
  "global_step": 625,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 7.094982624053955,
      "learning_rate": 2.5e-06,
      "loss": 1.6436,
      "num_input_tokens_seen": 7392,
      "step": 5,
      "train_runtime": 2.3118,
      "train_tokens_per_second": 3197.452
    },
    {
      "epoch": 0.08,
      "grad_norm": 6.705528736114502,
      "learning_rate": 5.625e-06,
      "loss": 1.637,
      "num_input_tokens_seen": 14912,
      "step": 10,
      "train_runtime": 3.2782,
      "train_tokens_per_second": 4548.769
    },
    {
      "epoch": 0.12,
      "grad_norm": 5.521490573883057,
      "learning_rate": 8.750000000000001e-06,
      "loss": 1.5152,
      "num_input_tokens_seen": 21888,
      "step": 15,
      "train_runtime": 4.237,
      "train_tokens_per_second": 5165.928
    },
    {
      "epoch": 0.16,
      "grad_norm": 4.922623157501221,
      "learning_rate": 1.1875e-05,
      "loss": 1.3108,
      "num_input_tokens_seen": 28992,
      "step": 20,
      "train_runtime": 5.1948,
      "train_tokens_per_second": 5580.979
    },
    {
      "epoch": 0.2,
      "grad_norm": 4.244542598724365,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 0.9351,
      "num_input_tokens_seen": 36256,
      "step": 25,
      "train_runtime": 6.1533,
      "train_tokens_per_second": 5892.105
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.9128408432006836,
      "learning_rate": 1.8125e-05,
      "loss": 0.4757,
      "num_input_tokens_seen": 43328,
      "step": 30,
      "train_runtime": 7.1065,
      "train_tokens_per_second": 6096.958
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0711736679077148,
      "learning_rate": 1.9999438672536202e-05,
      "loss": 0.171,
      "num_input_tokens_seen": 50848,
      "step": 35,
      "train_runtime": 8.0572,
      "train_tokens_per_second": 6310.882
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0285099744796753,
      "learning_rate": 1.9993124462265045e-05,
      "loss": 0.0594,
      "num_input_tokens_seen": 57920,
      "step": 40,
      "train_runtime": 9.017,
      "train_tokens_per_second": 6423.412
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5546267032623291,
      "learning_rate": 1.99797988273698e-05,
      "loss": 0.0528,
      "num_input_tokens_seen": 65024,
      "step": 45,
      "train_runtime": 9.9709,
      "train_tokens_per_second": 6521.376
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.401042103767395,
      "learning_rate": 1.995947111744728e-05,
      "loss": 0.0391,
      "num_input_tokens_seen": 72192,
      "step": 50,
      "train_runtime": 10.9241,
      "train_tokens_per_second": 6608.531
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.03340782970190048,
      "eval_runtime": 1.2931,
      "eval_samples_per_second": 77.332,
      "eval_steps_per_second": 19.333,
      "num_input_tokens_seen": 72192,
      "step": 50
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.39589014649391174,
      "learning_rate": 1.993215559492426e-05,
      "loss": 0.0349,
      "num_input_tokens_seen": 79392,
      "step": 55,
      "train_runtime": 13.1723,
      "train_tokens_per_second": 6027.189
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.2830612361431122,
      "learning_rate": 1.9897871425050598e-05,
      "loss": 0.0324,
      "num_input_tokens_seen": 86720,
      "step": 60,
      "train_runtime": 14.1266,
      "train_tokens_per_second": 6138.791
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.31500133872032166,
      "learning_rate": 1.9856642662452437e-05,
      "loss": 0.0147,
      "num_input_tokens_seen": 94144,
      "step": 65,
      "train_runtime": 15.0816,
      "train_tokens_per_second": 6242.289
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3499331772327423,
      "learning_rate": 1.980849823425486e-05,
      "loss": 0.0186,
      "num_input_tokens_seen": 101408,
      "step": 70,
      "train_runtime": 16.0367,
      "train_tokens_per_second": 6323.511
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7393140196800232,
      "learning_rate": 1.975347191978591e-05,
      "loss": 0.0199,
      "num_input_tokens_seen": 108768,
      "step": 75,
      "train_runtime": 16.9979,
      "train_tokens_per_second": 6398.895
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4548666477203369,
      "learning_rate": 1.969160232687616e-05,
      "loss": 0.0216,
      "num_input_tokens_seen": 116224,
      "step": 80,
      "train_runtime": 17.9588,
      "train_tokens_per_second": 6471.699
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.11559439450502396,
      "learning_rate": 1.9622932864770538e-05,
      "loss": 0.0192,
      "num_input_tokens_seen": 123680,
      "step": 85,
      "train_runtime": 18.9205,
      "train_tokens_per_second": 6536.832
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.268882691860199,
      "learning_rate": 1.9547511713671264e-05,
      "loss": 0.0109,
      "num_input_tokens_seen": 131168,
      "step": 90,
      "train_runtime": 19.8803,
      "train_tokens_per_second": 6597.903
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.4539923071861267,
      "learning_rate": 1.946539179093347e-05,
      "loss": 0.011,
      "num_input_tokens_seen": 138464,
      "step": 95,
      "train_runtime": 20.8398,
      "train_tokens_per_second": 6644.211
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.07095842808485031,
      "learning_rate": 1.9376630713937043e-05,
      "loss": 0.0049,
      "num_input_tokens_seen": 145728,
      "step": 100,
      "train_runtime": 21.7938,
      "train_tokens_per_second": 6686.679
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.008770585060119629,
      "eval_runtime": 1.2964,
      "eval_samples_per_second": 77.14,
      "eval_steps_per_second": 19.285,
      "num_input_tokens_seen": 145728,
      "step": 100
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.12967832386493683,
      "learning_rate": 1.928129075966085e-05,
      "loss": 0.0102,
      "num_input_tokens_seen": 152736,
      "step": 105,
      "train_runtime": 25.6361,
      "train_tokens_per_second": 5957.86
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.30469003319740295,
      "learning_rate": 1.9179438820987645e-05,
      "loss": 0.0087,
      "num_input_tokens_seen": 159872,
      "step": 110,
      "train_runtime": 26.5937,
      "train_tokens_per_second": 6011.649
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.2631136476993561,
      "learning_rate": 1.9071146359770384e-05,
      "loss": 0.0084,
      "num_input_tokens_seen": 167168,
      "step": 115,
      "train_runtime": 27.5519,
      "train_tokens_per_second": 6067.39
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.01678370125591755,
      "learning_rate": 1.895648935669278e-05,
      "loss": 0.008,
      "num_input_tokens_seen": 174624,
      "step": 120,
      "train_runtime": 28.5405,
      "train_tokens_per_second": 6118.455
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.0992836952209473,
      "learning_rate": 1.8835548257959413e-05,
      "loss": 0.0123,
      "num_input_tokens_seen": 181920,
      "step": 125,
      "train_runtime": 29.5011,
      "train_tokens_per_second": 6166.551
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.1451103687286377,
      "learning_rate": 1.8708407918852608e-05,
      "loss": 0.0033,
      "num_input_tokens_seen": 189088,
      "step": 130,
      "train_runtime": 30.4619,
      "train_tokens_per_second": 6207.364
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.03536295145750046,
      "learning_rate": 1.857515754419592e-05,
      "loss": 0.0007,
      "num_input_tokens_seen": 196224,
      "step": 135,
      "train_runtime": 31.4178,
      "train_tokens_per_second": 6245.636
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.291755348443985,
      "learning_rate": 1.8435890625765776e-05,
      "loss": 0.0047,
      "num_input_tokens_seen": 203584,
      "step": 140,
      "train_runtime": 32.3738,
      "train_tokens_per_second": 6288.534
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.013837922364473343,
      "learning_rate": 1.8290704876695325e-05,
      "loss": 0.0023,
      "num_input_tokens_seen": 210720,
      "step": 145,
      "train_runtime": 33.3306,
      "train_tokens_per_second": 6322.128
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.012033270671963692,
      "learning_rate": 1.8139702162916485e-05,
      "loss": 0.0013,
      "num_input_tokens_seen": 218016,
      "step": 150,
      "train_runtime": 34.2881,
      "train_tokens_per_second": 6358.359
    },
    {
      "epoch": 1.2,
      "eval_loss": 0.004416206385940313,
      "eval_runtime": 1.3008,
      "eval_samples_per_second": 76.875,
      "eval_steps_per_second": 19.219,
      "num_input_tokens_seen": 218016,
      "step": 150
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.19142219424247742,
      "learning_rate": 1.7982988431688266e-05,
      "loss": 0.001,
      "num_input_tokens_seen": 225152,
      "step": 155,
      "train_runtime": 36.5459,
      "train_tokens_per_second": 6160.803
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.15555016696453094,
      "learning_rate": 1.782067363726153e-05,
      "loss": 0.0068,
      "num_input_tokens_seen": 232864,
      "step": 160,
      "train_runtime": 37.5525,
      "train_tokens_per_second": 6201.033
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.404926598072052,
      "learning_rate": 1.765287166373237e-05,
      "loss": 0.0059,
      "num_input_tokens_seen": 240128,
      "step": 165,
      "train_runtime": 38.5145,
      "train_tokens_per_second": 6234.748
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.162884920835495,
      "learning_rate": 1.7479700245138184e-05,
      "loss": 0.0011,
      "num_input_tokens_seen": 247360,
      "step": 170,
      "train_runtime": 39.4846,
      "train_tokens_per_second": 6264.726
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.033743806183338165,
      "learning_rate": 1.730128088285255e-05,
      "loss": 0.005,
      "num_input_tokens_seen": 254336,
      "step": 175,
      "train_runtime": 40.4435,
      "train_tokens_per_second": 6288.679
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.02901638112962246,
      "learning_rate": 1.7117738760336846e-05,
      "loss": 0.0019,
      "num_input_tokens_seen": 261728,
      "step": 180,
      "train_runtime": 41.3988,
      "train_tokens_per_second": 6322.117
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.007654078770428896,
      "learning_rate": 1.6929202655308414e-05,
      "loss": 0.0002,
      "num_input_tokens_seen": 268800,
      "step": 185,
      "train_runtime": 42.3527,
      "train_tokens_per_second": 6346.706
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.005598580464720726,
      "learning_rate": 1.6735804849386914e-05,
      "loss": 0.0014,
      "num_input_tokens_seen": 275904,
      "step": 190,
      "train_runtime": 43.3077,
      "train_tokens_per_second": 6370.778
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.03547881916165352,
      "learning_rate": 1.6537681035282247e-05,
      "loss": 0.0005,
      "num_input_tokens_seen": 283072,
      "step": 195,
      "train_runtime": 44.2629,
      "train_tokens_per_second": 6395.242
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.005882476456463337,
      "learning_rate": 1.6334970221589182e-05,
      "loss": 0.0009,
      "num_input_tokens_seen": 290208,
      "step": 200,
      "train_runtime": 45.2175,
      "train_tokens_per_second": 6418.045
    },
    {
      "epoch": 1.6,
      "eval_loss": 0.0050438628531992435,
      "eval_runtime": 1.3033,
      "eval_samples_per_second": 76.727,
      "eval_steps_per_second": 19.182,
      "num_input_tokens_seen": 290208,
      "step": 200
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.011644620448350906,
      "learning_rate": 1.6127814635255462e-05,
      "loss": 0.0006,
      "num_input_tokens_seen": 297728,
      "step": 205,
      "train_runtime": 49.4321,
      "train_tokens_per_second": 6022.968
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.10502446442842484,
      "learning_rate": 1.5916359621791847e-05,
      "loss": 0.0011,
      "num_input_tokens_seen": 305216,
      "step": 210,
      "train_runtime": 50.3885,
      "train_tokens_per_second": 6057.259
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.012453307397663593,
      "learning_rate": 1.570075354329408e-05,
      "loss": 0.0004,
      "num_input_tokens_seen": 312544,
      "step": 215,
      "train_runtime": 51.3427,
      "train_tokens_per_second": 6087.404
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.06093165650963783,
      "learning_rate": 1.5481147674348366e-05,
      "loss": 0.0028,
      "num_input_tokens_seen": 320064,
      "step": 220,
      "train_runtime": 52.2957,
      "train_tokens_per_second": 6120.272
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.13098661601543427,
      "learning_rate": 1.525769609589335e-05,
      "loss": 0.0005,
      "num_input_tokens_seen": 327104,
      "step": 225,
      "train_runtime": 53.2474,
      "train_tokens_per_second": 6143.101
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.04073971137404442,
      "learning_rate": 1.5030555587113091e-05,
      "loss": 0.0006,
      "num_input_tokens_seen": 334432,
      "step": 230,
      "train_runtime": 54.2007,
      "train_tokens_per_second": 6170.248
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6748815178871155,
      "learning_rate": 1.4799885515436912e-05,
      "loss": 0.0035,
      "num_input_tokens_seen": 341440,
      "step": 235,
      "train_runtime": 55.1547,
      "train_tokens_per_second": 6190.585
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.0017964153084903955,
      "learning_rate": 1.4565847724723225e-05,
      "loss": 0.0011,
      "num_input_tokens_seen": 348576,
      "step": 240,
      "train_runtime": 56.1081,
      "train_tokens_per_second": 6212.583
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.0019499375484883785,
      "learning_rate": 1.4328606421705868e-05,
      "loss": 0.004,
      "num_input_tokens_seen": 355872,
      "step": 245,
      "train_runtime": 57.0601,
      "train_tokens_per_second": 6236.79
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5736840963363647,
      "learning_rate": 1.4088328060782573e-05,
      "loss": 0.0112,
      "num_input_tokens_seen": 363200,
      "step": 250,
      "train_runtime": 58.0101,
      "train_tokens_per_second": 6260.983
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.003111790167167783,
      "eval_runtime": 1.3222,
      "eval_samples_per_second": 75.631,
      "eval_steps_per_second": 18.908,
      "num_input_tokens_seen": 363200,
      "step": 250
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.10646505653858185,
      "learning_rate": 1.3845181227226423e-05,
      "loss": 0.001,
      "num_input_tokens_seen": 370400,
      "step": 255,
      "train_runtime": 60.2984,
      "train_tokens_per_second": 6142.787
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.029265698045492172,
      "learning_rate": 1.3599336518902228e-05,
      "loss": 0.0013,
      "num_input_tokens_seen": 377312,
      "step": 260,
      "train_runtime": 61.2532,
      "train_tokens_per_second": 6159.875
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.06429687887430191,
      "learning_rate": 1.3350966426570825e-05,
      "loss": 0.0018,
      "num_input_tokens_seen": 384640,
      "step": 265,
      "train_runtime": 62.2037,
      "train_tokens_per_second": 6183.551
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.14850875735282898,
      "learning_rate": 1.3100245212865279e-05,
      "loss": 0.0011,
      "num_input_tokens_seen": 391936,
      "step": 270,
      "train_runtime": 63.1533,
      "train_tokens_per_second": 6206.107
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.0014792742440477014,
      "learning_rate": 1.2847348790023858e-05,
      "loss": 0.0007,
      "num_input_tokens_seen": 399136,
      "step": 275,
      "train_runtime": 64.1195,
      "train_tokens_per_second": 6224.872
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.020714670419692993,
      "learning_rate": 1.259245459646567e-05,
      "loss": 0.0003,
      "num_input_tokens_seen": 406272,
      "step": 280,
      "train_runtime": 65.0726,
      "train_tokens_per_second": 6243.366
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.009112924337387085,
      "learning_rate": 1.2335741472295426e-05,
      "loss": 0.0003,
      "num_input_tokens_seen": 413568,
      "step": 285,
      "train_runtime": 66.0278,
      "train_tokens_per_second": 6263.544
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.16676470637321472,
      "learning_rate": 1.2077389533824789e-05,
      "loss": 0.0004,
      "num_input_tokens_seen": 420768,
      "step": 290,
      "train_runtime": 66.9792,
      "train_tokens_per_second": 6282.068
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.0011564984451979399,
      "learning_rate": 1.1817580047198287e-05,
      "loss": 0.0003,
      "num_input_tokens_seen": 428096,
      "step": 295,
      "train_runtime": 67.9339,
      "train_tokens_per_second": 6301.652
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.0023584107402712107,
      "learning_rate": 1.1556495301212485e-05,
      "loss": 0.0055,
      "num_input_tokens_seen": 435200,
      "step": 300,
      "train_runtime": 68.8927,
      "train_tokens_per_second": 6317.074
    },
    {
      "epoch": 2.4,
      "eval_loss": 0.0037333357613533735,
      "eval_runtime": 1.2912,
      "eval_samples_per_second": 77.449,
      "eval_steps_per_second": 19.362,
      "num_input_tokens_seen": 435200,
      "step": 300
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.00231945444829762,
      "learning_rate": 1.1294318479417618e-05,
      "loss": 0.0002,
      "num_input_tokens_seen": 442368,
      "step": 305,
      "train_runtime": 73.9821,
      "train_tokens_per_second": 5979.389
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.001225775689817965,
      "learning_rate": 1.1031233531591471e-05,
      "loss": 0.0001,
      "num_input_tokens_seen": 449920,
      "step": 310,
      "train_runtime": 74.9366,
      "train_tokens_per_second": 6004.007
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.2684342563152313,
      "learning_rate": 1.0767425044675634e-05,
      "loss": 0.0011,
      "num_input_tokens_seen": 456992,
      "step": 315,
      "train_runtime": 75.8914,
      "train_tokens_per_second": 6021.658
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.004825124051421881,
      "learning_rate": 1.0503078113264715e-05,
      "loss": 0.0002,
      "num_input_tokens_seen": 464352,
      "step": 320,
      "train_runtime": 76.8431,
      "train_tokens_per_second": 6042.859
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0021467211190611124,
      "learning_rate": 1.0238378209739366e-05,
      "loss": 0.0001,
      "num_input_tokens_seen": 471648,
      "step": 325,
      "train_runtime": 77.7923,
      "train_tokens_per_second": 6062.913
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.6223334074020386,
      "learning_rate": 9.973511054134259e-06,
      "loss": 0.0051,
      "num_input_tokens_seen": 478816,
      "step": 330,
      "train_runtime": 78.7418,
      "train_tokens_per_second": 6080.837
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.06548092514276505,
      "learning_rate": 9.708662483832279e-06,
      "loss": 0.0005,
      "num_input_tokens_seen": 485888,
      "step": 335,
      "train_runtime": 79.6962,
      "train_tokens_per_second": 6096.756
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.0027565844357013702,
      "learning_rate": 9.444018323176399e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 493152,
      "step": 340,
      "train_runtime": 80.6472,
      "train_tokens_per_second": 6114.932
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.006295195315033197,
      "learning_rate": 9.179764253090703e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 500384,
      "step": 345,
      "train_runtime": 81.6026,
      "train_tokens_per_second": 6131.958
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.01367019023746252,
      "learning_rate": 8.916085680802038e-06,
      "loss": 0.0012,
      "num_input_tokens_seen": 507424,
      "step": 350,
      "train_runtime": 82.5537,
      "train_tokens_per_second": 6146.59
    },
    {
      "epoch": 2.8,
      "eval_loss": 0.003876066766679287,
      "eval_runtime": 1.3023,
      "eval_samples_per_second": 76.786,
      "eval_steps_per_second": 19.196,
      "num_input_tokens_seen": 507424,
      "step": 350
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.00467269541695714,
      "learning_rate": 8.653167609753667e-06,
      "loss": 0.0037,
      "num_input_tokens_seen": 514816,
      "step": 355,
      "train_runtime": 84.8042,
      "train_tokens_per_second": 6070.645
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.0014137800317257643,
      "learning_rate": 8.391194509802294e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 522112,
      "step": 360,
      "train_runtime": 85.7534,
      "train_tokens_per_second": 6088.526
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.050120290368795395,
      "learning_rate": 8.130350187789387e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 529504,
      "step": 365,
      "train_runtime": 86.7052,
      "train_tokens_per_second": 6106.949
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.003201607847586274,
      "learning_rate": 7.870817658577743e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 536864,
      "step": 370,
      "train_runtime": 87.6619,
      "train_tokens_per_second": 6124.259
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.042537037283182144,
      "learning_rate": 7.61277901664372e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 544064,
      "step": 375,
      "train_runtime": 88.6248,
      "train_tokens_per_second": 6138.957
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.007069969084113836,
      "learning_rate": 7.356415308315201e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 551168,
      "step": 380,
      "train_runtime": 89.5849,
      "train_tokens_per_second": 6152.468
    },
    {
      "epoch": 3.08,
      "grad_norm": 0.0016073811566457152,
      "learning_rate": 7.101906404745006e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 558272,
      "step": 385,
      "train_runtime": 90.5387,
      "train_tokens_per_second": 6166.117
    },
    {
      "epoch": 3.12,
      "grad_norm": 0.008943263441324234,
      "learning_rate": 6.849430875708818e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 565216,
      "step": 390,
      "train_runtime": 91.4879,
      "train_tokens_per_second": 6178.039
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.0034947446547448635,
      "learning_rate": 6.5991658643161696e-06,
      "loss": 0.0038,
      "num_input_tokens_seen": 572384,
      "step": 395,
      "train_runtime": 92.4749,
      "train_tokens_per_second": 6189.612
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.0027218153700232506,
      "learning_rate": 6.3512869627224535e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 579680,
      "step": 400,
      "train_runtime": 93.4244,
      "train_tokens_per_second": 6204.806
    },
    {
      "epoch": 3.2,
      "eval_loss": 0.003433908335864544,
      "eval_runtime": 1.3114,
      "eval_samples_per_second": 76.256,
      "eval_steps_per_second": 19.064,
      "num_input_tokens_seen": 579680,
      "step": 400
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.005386108532547951,
      "learning_rate": 6.105968088929098e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 587200,
      "step": 405,
      "train_runtime": 97.5886,
      "train_tokens_per_second": 6017.094
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 0.018784774467349052,
      "learning_rate": 5.8633813647583505e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 594272,
      "step": 410,
      "train_runtime": 98.5488,
      "train_tokens_per_second": 6030.23
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.0011999007547274232,
      "learning_rate": 5.62369699508835e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 601312,
      "step": 415,
      "train_runtime": 99.4969,
      "train_tokens_per_second": 6043.525
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.004967959132045507,
      "learning_rate": 5.38708314843315e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 608960,
      "step": 420,
      "train_runtime": 100.4399,
      "train_tokens_per_second": 6062.93
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.0010889203986153007,
      "learning_rate": 5.153705838951495e-06,
      "loss": 0.0004,
      "num_input_tokens_seen": 616224,
      "step": 425,
      "train_runtime": 101.3914,
      "train_tokens_per_second": 6077.676
    },
    {
      "epoch": 3.44,
      "grad_norm": 0.005715887062251568,
      "learning_rate": 4.923728809967156e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 623552,
      "step": 430,
      "train_runtime": 102.3353,
      "train_tokens_per_second": 6093.227
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.12686356902122498,
      "learning_rate": 4.697313419082573e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 631264,
      "step": 435,
      "train_runtime": 103.2769,
      "train_tokens_per_second": 6112.347
    },
    {
      "epoch": 3.52,
      "grad_norm": 0.004452281631529331,
      "learning_rate": 4.474618524966313e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 638336,
      "step": 440,
      "train_runtime": 104.2215,
      "train_tokens_per_second": 6124.804
    },
    {
      "epoch": 3.56,
      "grad_norm": 0.5198068618774414,
      "learning_rate": 4.255800375893885e-06,
      "loss": 0.0053,
      "num_input_tokens_seen": 645760,
      "step": 445,
      "train_runtime": 105.1641,
      "train_tokens_per_second": 6140.501
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.010895857587456703,
      "learning_rate": 4.04101250012009e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 653248,
      "step": 450,
      "train_runtime": 106.1096,
      "train_tokens_per_second": 6156.351
    },
    {
      "epoch": 3.6,
      "eval_loss": 0.0036046362947672606,
      "eval_runtime": 1.2755,
      "eval_samples_per_second": 78.401,
      "eval_steps_per_second": 19.6,
      "num_input_tokens_seen": 653248,
      "step": 450
    },
    {
      "epoch": 3.64,
      "grad_norm": 0.005448261275887489,
      "learning_rate": 3.8304055981597495e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 660448,
      "step": 455,
      "train_runtime": 108.334,
      "train_tokens_per_second": 6096.404
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.011558587662875652,
      "learning_rate": 3.624127437052484e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 667776,
      "step": 460,
      "train_runtime": 109.2787,
      "train_tokens_per_second": 6110.761
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 0.0015591796254739165,
      "learning_rate": 3.4223227466857045e-06,
      "loss": 0.0004,
      "num_input_tokens_seen": 674944,
      "step": 465,
      "train_runtime": 110.2211,
      "train_tokens_per_second": 6123.544
    },
    {
      "epoch": 3.76,
      "grad_norm": 0.002196353627368808,
      "learning_rate": 3.2251331182484868e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 682112,
      "step": 470,
      "train_runtime": 111.1712,
      "train_tokens_per_second": 6135.691
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.0011376452166587114,
      "learning_rate": 3.0326969048877032e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 689376,
      "step": 475,
      "train_runtime": 112.1232,
      "train_tokens_per_second": 6148.379
    },
    {
      "epoch": 3.84,
      "grad_norm": 0.0009770984761416912,
      "learning_rate": 2.845149124636014e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 697024,
      "step": 480,
      "train_runtime": 113.0797,
      "train_tokens_per_second": 6164.007
    },
    {
      "epoch": 3.88,
      "grad_norm": 0.06582614034414291,
      "learning_rate": 2.6626213656798295e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 704352,
      "step": 485,
      "train_runtime": 114.0444,
      "train_tokens_per_second": 6176.121
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.0013161207316443324,
      "learning_rate": 2.485241694033793e-06,
      "loss": 0.0003,
      "num_input_tokens_seen": 711680,
      "step": 490,
      "train_runtime": 115.0087,
      "train_tokens_per_second": 6188.051
    },
    {
      "epoch": 3.96,
      "grad_norm": 0.005136311054229736,
      "learning_rate": 2.313134563686482e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 718656,
      "step": 495,
      "train_runtime": 115.9794,
      "train_tokens_per_second": 6196.412
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.0008357082260772586,
      "learning_rate": 2.1464207292803696e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 725792,
      "step": 500,
      "train_runtime": 116.9404,
      "train_tokens_per_second": 6206.51
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.003781458828598261,
      "eval_runtime": 1.3321,
      "eval_samples_per_second": 75.069,
      "eval_steps_per_second": 18.767,
      "num_input_tokens_seen": 725792,
      "step": 500
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.003185194218531251,
      "learning_rate": 1.9852171613873837e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 732864,
      "step": 505,
      "train_runtime": 120.8809,
      "train_tokens_per_second": 6062.694
    },
    {
      "epoch": 4.08,
      "grad_norm": 0.005603047553449869,
      "learning_rate": 1.8296369644394562e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 740096,
      "step": 510,
      "train_runtime": 121.848,
      "train_tokens_per_second": 6073.929
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.0010688947513699532,
      "learning_rate": 1.6797892973716057e-06,
      "loss": 0.0002,
      "num_input_tokens_seen": 747392,
      "step": 515,
      "train_runtime": 122.8114,
      "train_tokens_per_second": 6085.689
    },
    {
      "epoch": 4.16,
      "grad_norm": 0.0008642789325676858,
      "learning_rate": 1.535779297033344e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 754912,
      "step": 520,
      "train_runtime": 123.7732,
      "train_tokens_per_second": 6099.154
    },
    {
      "epoch": 4.2,
      "grad_norm": 0.002334616146981716,
      "learning_rate": 1.397708004422047e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 762176,
      "step": 525,
      "train_runtime": 124.7405,
      "train_tokens_per_second": 6110.093
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.0012261364609003067,
      "learning_rate": 1.2656722937900534e-06,
      "loss": 0.002,
      "num_input_tokens_seen": 769664,
      "step": 530,
      "train_runtime": 125.7074,
      "train_tokens_per_second": 6122.661
    },
    {
      "epoch": 4.28,
      "grad_norm": 0.01935139112174511,
      "learning_rate": 1.1397648046753062e-06,
      "loss": 0.0001,
      "num_input_tokens_seen": 777152,
      "step": 535,
      "train_runtime": 126.6777,
      "train_tokens_per_second": 6134.875
    },
    {
      "epoch": 4.32,
      "grad_norm": 0.008282871916890144,
      "learning_rate": 1.020073876903147e-06,
      "loss": 0.0012,
      "num_input_tokens_seen": 784288,
      "step": 540,
      "train_runtime": 127.6411,
      "train_tokens_per_second": 6144.481
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.009212779812514782,
      "learning_rate": 9.066834886048748e-07,
      "loss": 0.0002,
      "num_input_tokens_seen": 791360,
      "step": 545,
      "train_runtime": 128.6086,
      "train_tokens_per_second": 6153.243
    },
    {
      "epoch": 4.4,
      "grad_norm": 0.0009073670953512192,
      "learning_rate": 7.996731972966287e-07,
      "loss": 0.0003,
      "num_input_tokens_seen": 798528,
      "step": 550,
      "train_runtime": 129.5717,
      "train_tokens_per_second": 6162.829
    },
    {
      "epoch": 4.4,
      "eval_loss": 0.0037032077088952065,
      "eval_runtime": 1.3188,
      "eval_samples_per_second": 75.829,
      "eval_steps_per_second": 18.957,
      "num_input_tokens_seen": 798528,
      "step": 550
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.0010972783202305436,
      "learning_rate": 6.991180840598388e-07,
      "loss": 0.003,
      "num_input_tokens_seen": 805568,
      "step": 555,
      "train_runtime": 131.8644,
      "train_tokens_per_second": 6109.064
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.050488363951444626,
      "learning_rate": 6.050887008624817e-07,
      "loss": 0.0002,
      "num_input_tokens_seen": 812832,
      "step": 560,
      "train_runtime": 132.8299,
      "train_tokens_per_second": 6119.344
    },
    {
      "epoch": 4.52,
      "grad_norm": 0.0041364626958966255,
      "learning_rate": 5.176510210580577e-07,
      "loss": 0.0001,
      "num_input_tokens_seen": 820000,
      "step": 565,
      "train_runtime": 133.793,
      "train_tokens_per_second": 6128.871
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 0.0011067049345001578,
      "learning_rate": 4.3686639309705183e-07,
      "loss": 0.0001,
      "num_input_tokens_seen": 827648,
      "step": 570,
      "train_runtime": 134.7534,
      "train_tokens_per_second": 6141.943
    },
    {
      "epoch": 4.6,
      "grad_norm": 0.0012045457260683179,
      "learning_rate": 3.627914974833302e-07,
      "loss": 0.0002,
      "num_input_tokens_seen": 834944,
      "step": 575,
      "train_runtime": 135.7187,
      "train_tokens_per_second": 6152.017
    },
    {
      "epoch": 4.64,
      "grad_norm": 0.028299950063228607,
      "learning_rate": 2.9547830700569545e-07,
      "loss": 0.0002,
      "num_input_tokens_seen": 842112,
      "step": 580,
      "train_runtime": 136.6805,
      "train_tokens_per_second": 6161.169
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.01337027084082365,
      "learning_rate": 2.3497405027247845e-07,
      "loss": 0.0001,
      "num_input_tokens_seen": 849440,
      "step": 585,
      "train_runtime": 137.6452,
      "train_tokens_per_second": 6171.23
    },
    {
      "epoch": 4.72,
      "grad_norm": 0.0032394584268331528,
      "learning_rate": 1.8132117857477593e-07,
      "loss": 0.0001,
      "num_input_tokens_seen": 857120,
      "step": 590,
      "train_runtime": 138.6083,
      "train_tokens_per_second": 6183.755
    },
    {
      "epoch": 4.76,
      "grad_norm": 0.0012313573388382792,
      "learning_rate": 1.345573361015706e-07,
      "loss": 0.0001,
      "num_input_tokens_seen": 864448,
      "step": 595,
      "train_runtime": 139.5708,
      "train_tokens_per_second": 6193.619
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.01377703808248043,
      "learning_rate": 9.471533352762962e-08,
      "loss": 0.0001,
      "num_input_tokens_seen": 871552,
      "step": 600,
      "train_runtime": 140.5316,
      "train_tokens_per_second": 6201.823
    },
    {
      "epoch": 4.8,
      "eval_loss": 0.0038835147861391306,
      "eval_runtime": 1.3081,
      "eval_samples_per_second": 76.448,
      "eval_steps_per_second": 19.112,
      "num_input_tokens_seen": 871552,
      "step": 600
    },
    {
      "epoch": 4.84,
      "grad_norm": 0.006501771975308657,
      "learning_rate": 6.182312499271703e-08,
      "loss": 0.0001,
      "num_input_tokens_seen": 878560,
      "step": 605,
      "train_runtime": 144.4118,
      "train_tokens_per_second": 6083.714
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.012748992070555687,
      "learning_rate": 3.59037884882818e-08,
      "loss": 0.0002,
      "num_input_tokens_seen": 885920,
      "step": 610,
      "train_runtime": 145.3747,
      "train_tokens_per_second": 6094.045
    },
    {
      "epoch": 4.92,
      "grad_norm": 0.0013732695952057838,
      "learning_rate": 1.697550966535566e-08,
      "loss": 0.0001,
      "num_input_tokens_seen": 893312,
      "step": 615,
      "train_runtime": 146.3374,
      "train_tokens_per_second": 6104.469
    },
    {
      "epoch": 4.96,
      "grad_norm": 0.06738247722387314,
      "learning_rate": 5.051569075056328e-09,
      "loss": 0.0002,
      "num_input_tokens_seen": 900576,
      "step": 620,
      "train_runtime": 147.2976,
      "train_tokens_per_second": 6113.988
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.028598126024007797,
      "learning_rate": 1.4033285061554325e-10,
      "loss": 0.0002,
      "num_input_tokens_seen": 907648,
      "step": 625,
      "train_runtime": 148.2574,
      "train_tokens_per_second": 6122.11
    },
    {
      "epoch": 5.0,
      "num_input_tokens_seen": 907648,
      "step": 625,
      "total_flos": 1.085951824625664e+16,
      "train_loss": 0.06549765138756483,
      "train_runtime": 149.8762,
      "train_samples_per_second": 33.361,
      "train_steps_per_second": 4.17
    }
  ],
  "logging_steps": 5,
  "max_steps": 625,
  "num_input_tokens_seen": 907648,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.085951824625664e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
